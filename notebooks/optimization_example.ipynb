{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97d099ec",
   "metadata": {},
   "source": [
    "## Optimization Example Notebook\n",
    "Here is an example of how to setup a simple optimization test using the gradients calculated using \n",
    "JAX's automatic differentiation capabilities. \n",
    "\n",
    "In this notebook we setup a forward function wrapper, loss function to optimize over, and a basic gradient desent optimization loop as a basic optimization example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8b8794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jcm.model import Model\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jcm.physics.speedy.speedy_physics import SpeedyPhysics\n",
    "from jcm.physics.speedy.params import Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f4387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup function requirements\n",
    "def create_model(parameters, time_step = 30, save_interval = 1.0, total_time = 5.0, layers = 8): \n",
    "    '''\n",
    "    Returns speedy model with given parameters and specifications\n",
    "\n",
    "    Args: \n",
    "        parameters: parameters object type (jcm.paramters)\n",
    "        time_step: Model time step in minutes\n",
    "        save_interval: Save interval in days\n",
    "        total_time: Total integration time in days\n",
    "        layers: Number of vertical layers\n",
    "    '''\n",
    "    model = Model(time_step = time_step, \n",
    "                        save_interval = save_interval, \n",
    "                        total_time = total_time, \n",
    "                        layers = layers,\n",
    "                        physics = SpeedyPhysics(parameters = parameters))\n",
    "    return model\n",
    "\n",
    "def average_pred(predictions):\n",
    "    '''\n",
    "    Average over predicitions\n",
    "    '''\n",
    "    leaves_d = jax.tree_util.tree_leaves(predictions['dynamics'])\n",
    "    avgs_d = jnp.array([jnp.mean(leaf) for leaf in leaves_d])\n",
    "    leaves_p = jax.tree_util.tree_leaves(predictions['physics'])\n",
    "    avgs_p = jnp.array([jnp.mean(leaf) for leaf in leaves_p])\n",
    "    return jnp.concatenate((avgs_d, avgs_p))\n",
    "\n",
    "\n",
    "def forward_model_wrapper(theta, theta_keys, state = None, parameters = None, args = ()):\n",
    "    '''\n",
    "    Returns forward model run collapsed into a single vector\n",
    "\n",
    "    Args: \n",
    "        theta: parameters of interest (find the parameters that minimize the loss function)\n",
    "        theta_keys: dictionary with parameter names \n",
    "        state: state object type (jcm.State)\n",
    "        parameters: parameters object type (jcm.paramters)\n",
    "        args: additional arguments for creating the model\n",
    "    '''\n",
    "    if parameters is None:\n",
    "        parameters = Parameters.default()\n",
    "\n",
    "    ii = 0\n",
    "    for attr, params in theta_keys.items():\n",
    "        for param in params:\n",
    "            setattr(getattr(parameters, attr), param, theta[ii])\n",
    "            ii += 1\n",
    "        \n",
    "    model = create_model(parameters, *args) \n",
    "    if state is None: \n",
    "        state = model.get_initial_state()\n",
    "    _, model_predictions = model.unroll(state)\n",
    "    return average_pred(model_predictions)\n",
    "   \n",
    "\n",
    "def loss_function(theta, forward_model, y, R_inv_sqrt, args = ()): \n",
    "    '''\n",
    "    Returns data-model misfit (i.e. loss function to optimize over)\n",
    "\n",
    "    Args: \n",
    "        theta: parameters of interest (find the parameters that minimize the loss function)\n",
    "        forward_model: forward run through model with output the same shape as y\n",
    "        y: data to compare model to (must be 1D vector)\n",
    "        R_inv_sqrt: inverse square root of R (the assumed data errors associated to data)\n",
    "        args: additional forward model function inputs\n",
    "    '''\n",
    "\n",
    "    return 0.5*jnp.linalg.norm(R_inv_sqrt*(y - forward_model(theta, *args)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97af637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward function for true parameters\n",
    "true_params = Parameters.default()  # True parameters are default parameters\n",
    "model = create_model(true_params) # Create model that will run for 5 days\n",
    "state = model.get_initial_state()\n",
    "final_state, predictions = model.unroll(state)  # run model forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cd13930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic data\n",
    "y = average_pred(predictions)\n",
    "# Assumed errors\n",
    "R_inv_sqrt = jnp.ones_like(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cae2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paramters to estimate\n",
    "params = Parameters.default()  # Set all other parameters\n",
    "theta = jnp.array([jnp.array(0.10)])  # Choose initial guess for estimating parameter/s\n",
    "theta_keys = {\"shortwave_radiation\": [\"albcls\"]} # Define parameter/s to be estimated\n",
    "\n",
    "# Define hyperparameters\n",
    "step_size = 2e-6\n",
    "num_iters = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3233e731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function gradient function\n",
    "grad_loss_fn = jax.grad(loss_function, argnums = 0) # Uses jax.grad to calculate gradient\n",
    "\n",
    "# Optimization loop\n",
    "thetas_GD = []\n",
    "thetas_GD.append(theta)\n",
    "for i in range(num_iters): # Loop run time will take a while on laptop (about 5 minutes per iteration)\n",
    "    grad = grad_loss_fn(theta, forward_model_wrapper, y, R_inv_sqrt,\n",
    "                         args = (theta_keys, state, params)) # Compute gradient\n",
    "    print(\"The gradient is: \", grad[0])\n",
    "    theta -= step_size * grad[0]  # Gradient descent update\n",
    "    print(f\"Iteration {i+1}: theta = {theta}\")\n",
    "    thetas_GD.append(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating loss function over [0,1] range\n",
    "params = Parameters.default()  # Set default paramters\n",
    "# Loss function loop for albcls\n",
    "thetas = jnp.arange(0.0, 1.0, 0.025)\n",
    "losses = []\n",
    "for ii in range(len(thetas)):\n",
    "    theta = jnp.array([jnp.array(thetas[ii])])\n",
    "    losses.append(loss_function(theta, forward_model_wrapper, y, R_inv_sqrt,\n",
    "                         args = (theta_keys, state, params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c09a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(thetas, losses, linewidth = 3, color = \"darkgreen\",  # plot loss function\n",
    "         zorder = 0, label = \"Loss function\")\n",
    "coeffs = jnp.polyfit(thetas, losses, deg=2) # plot gradient descent steps\n",
    "gd_thetas = jnp.array(thetas_GD) \n",
    "gd_losses = jnp.polyval(coeffs, gd_thetas)\n",
    "plt.scatter(gd_thetas, gd_losses, label = \"Optimization iterations\",\n",
    "            s = 80, marker = 'o', color = \"orange\", zorder = 1, edgecolors = \"black\")\n",
    "plt.scatter(0.50, 0, label = \"Truth\", # plot truth\n",
    "            marker = \"*\", color = \"yellow\", zorder = 2, s = 200, edgecolors = \"black\")\n",
    "plt.xlabel(\"Stratiform cloud albedo (for st. cloud cover = 1)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-gcm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
